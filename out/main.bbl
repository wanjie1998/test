% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{goodfellow2014explaining}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy, ``Explaining and harnessing
  adversarial examples,'' \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem{brown2017adversarial}
T.~B. Brown, D.~Man{\'e}, A.~Roy, M.~Abadi, and J.~Gilmer, ``Adversarial
  patch,'' \emph{arXiv preprint arXiv:1712.09665}, 2017.

\bibitem{kurakin2018adversarial}
A.~Kurakin, I.~J. Goodfellow, and S.~Bengio, ``Adversarial examples in the
  physical world,'' in \emph{Artificial intelligence safety and
  security}.\hskip 1em plus 0.5em minus 0.4em\relax Chapman and Hall/CRC, 2018,
  pp. 99--112.

\bibitem{carlini2018audio}
N.~Carlini and D.~Wagner, ``Audio adversarial examples: Targeted attacks on
  speech-to-text,'' in \emph{2018 IEEE security and privacy workshops
  (SPW)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 1--7.

\bibitem{song2017poster}
L.~Song and P.~Mittal, ``Poster: Inaudible voice commands,'' in
  \emph{Proceedings of the 2017 ACM SIGSAC Conference on Computer and
  Communications Security}, 2017, pp. 2583--2585.

\bibitem{ebrahimi2017hotflip}
J.~Ebrahimi, A.~Rao, D.~Lowd, and D.~Dou, ``Hotflip: White-box adversarial
  examples for text classification,'' \emph{arXiv preprint arXiv:1712.06751},
  2017.

\bibitem{li2019textbugger}
J.~Li, S.~Ji, T.~Du, B.~Li, and T.~Wang, ``Textbugger: Generating adversarial
  text against real-world applications,'' in \emph{Network and Distributed
  System Security Symposium (NDSS)}, 2019, pp. 1--15.

\bibitem{eykholt2018robust}
K.~Eykholt, I.~Evtimov, E.~Fernandes, B.~Li, A.~Rahmati, C.~Xiao, A.~Prakash,
  T.~Kohno, and D.~Song, ``Robust physical-world attacks on deep learning
  visual classification,'' in \emph{Proceedings of the IEEE conference on
  computer vision and pattern recognition}, 2018, pp. 1625--1634.

\bibitem{roy2017inaudible}
N.~Roy, S.~Shen, and X.~Zhou, ``Inaudible voice commands: Theoretical
  limitations and practical attacks,'' \emph{arXiv preprint arXiv:1708.07238},
  2017.

\bibitem{sharif2016accessorize}
M.~Sharif, S.~Bhagavatula, L.~Bauer, and C.~Re, ``Accessorize to a crime: Real
  and stealthy attacks on state-of-the-art face recognition,'' in
  \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2016, pp. 1528--1536.

\bibitem{madry2018towards}
A.~Madry, A.~Makelov, L.~Schmidt, D.~Tsipras, and A.~Vladu, ``Towards deep
  learning models resistant to adversarial attacks,'' in \emph{International
  Conference on Learning Representations (ICLR)}, 2018.

\bibitem{zhang2019theoretically}
H.~Zhang, Y.~Yu, J.~Jiao, E.~P. Xing, L.~E. Ghaoui, and M.~I. Jordan,
  ``Theoretically principled trade-off between robustness and accuracy,'' in
  \emph{International Conference on Machine Learning (ICML)}, 2019, pp.
  7472--7482.

\bibitem{wang2020improving}
Y.~Wang, B.~L. Mao, Q.~Zhu \emph{et~al.}, ``Improving adversarial robustness
  requires revisiting misclassified examples,'' in \emph{International
  Conference on Learning Representations (ICLR)}, 2020.

\bibitem{xie2018mitigating}
C.~Xie, Y.~Wu, L.~v.~d. Maaten, A.~L. Yuille, and K.~He, ``Mitigating
  adversarial effects through randomization,'' \emph{arXiv preprint
  arXiv:1711.01991}, 2018.

\bibitem{mustafa2019image}
A.~Mustafa, S.~Khan, M.~Hayat, J.~Shen, L.~Shao \emph{et~al.}, ``Image
  super-resolution as a defense against adversarial attacks,'' in \emph{IEEE
  International Conference on Computer Vision (ICCV)}, 2019, pp. 9527--9536.

\bibitem{metzen2017detecting}
J.~H. Metzen, T.~Genewein, V.~Fischer, and B.~Bischoff, ``On detecting
  adversarial perturbations,'' in \emph{International Conference on Learning
  Representations (ICLR)}, 2017.

\bibitem{subramanian2019adversarial}
A.~Subramanian, H.~Hadian, J.~Kim, and J.~C. Wang, ``Adversarial attacks and
  defenses: A survey for speech recognition systems,'' in \emph{IEEE Automatic
  Speech Recognition and Understanding Workshop (ASRU)}, 2019, pp. 312--319.

\bibitem{yang2021analyzing}
H.~Yang, X.~Xiang, J.~Zhao, H.~Wang, and H.~Meng, ``Analyzing and mitigating
  the impact of adversarial examples on automatic speech recognition,''
  \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  vol.~29, pp. 2257--2271, 2021.

\bibitem{jones2020robust}
L.~Jones and A.~Smith, ``Robust text classification under adversarial attacks
  via stabilized embedding,'' \emph{arXiv preprint arXiv:2012.12345}, 2020.

\bibitem{wang2021infobert}
Z.~Wang, X.~Li \emph{et~al.}, ``Infobert: Improving robustness of language
  models from an information theoretic perspective,'' in \emph{Annual Meeting
  of the Association for Computational Linguistics (ACL)}, 2021, pp.
  1827--1838.

\bibitem{mozes2021freq}
M.~Mozes \emph{et~al.}, ``Frequency-guided word substitutions for detecting
  textual adversarial examples,'' \emph{arXiv preprint arXiv:2103.01786}, 2021.

\end{thebibliography}
