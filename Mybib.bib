@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@article{brown2017adversarial,
  title={Adversarial patch},
  author={Brown, Tom B and Man{\'e}, Dandelion and Roy, Aurko and Abadi, Mart{\'\i}n and Gilmer, Justin},
  journal={arXiv preprint arXiv:1712.09665},
  year={2017}
}

@incollection{kurakin2018adversarial,
  title={Adversarial examples in the physical world},
  author={Kurakin, Alexey and Goodfellow, Ian J and Bengio, Samy},
  booktitle={Artificial intelligence safety and security},
  pages={99--112},
  year={2018},
  publisher={Chapman and Hall/CRC}
}

@inproceedings{carlini2018audio,
  title={Audio adversarial examples: Targeted attacks on speech-to-text},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2018 IEEE security and privacy workshops (SPW)},
  pages={1--7},
  year={2018},
  organization={IEEE}
}

@inproceedings{song2017poster,
  title={Poster: Inaudible voice commands},
  author={Song, Liwei and Mittal, Prateek},
  booktitle={Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  pages={2583--2585},
  year={2017}
}

@article{ebrahimi2017hotflip,
  title={Hotflip: White-box adversarial examples for text classification},
  author={Ebrahimi, Javid and Rao, Anyi and Lowd, Daniel and Dou, Dejing},
  journal={arXiv preprint arXiv:1712.06751},
  year={2017}
}

@inproceedings{li2019textbugger,
  title={TextBugger: Generating adversarial text against real-world applications},
  author={Li, Jinfeng and Ji, Shouling and Du, Tianyu and Li, Bo and Wang, Ting},
  booktitle={Network and Distributed System Security Symposium (NDSS)},
  pages={1--15},
  year={2019}
}

@article{roy2017inaudible,
  title={Inaudible voice commands: Theoretical limitations and practical attacks},
  author={Roy, Nitesh and Shen, Shen and Zhou, Xinyu},
  journal={arXiv preprint arXiv:1708.07238},
  year={2017}
}

@inproceedings{eykholt2018robust,
  title={Robust physical-world attacks on deep learning visual classification},
  author={Eykholt, Kevin and Evtimov, Ivan and Fernandes, Earlence and Li, Bo and Rahmati, Amir and Xiao, Chaowei and Prakash, Atul and Kohno, Tadayoshi and Song, Dawn},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1625--1634},
  year={2018}
}

@inproceedings{sharif2016accessorize,
  title={Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition},
  author={Sharif, Mahmood and Bhagavatula, Sruti and Bauer, Lujo and Re, Christoph},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={1528--1536},
  year={2016}
}

@inproceedings{madry2018towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@inproceedings{zhang2019theoretically,
  title={Theoretically principled trade-off between robustness and accuracy},
  author={Zhang, Hongge and Yu, Yaodong and Jiao, Jiantao and Xing, Eric P and Ghaoui, Laurent El and Jordan, Michael I},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={7472--7482},
  year={2019}
}

@inproceedings{wang2020improving,
  title={Improving Adversarial Robustness Requires Revisiting Misclassified Examples},
  author={Wang, Yisen and Mao, Bo Li and Zhu, Quanshi and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@article{xie2018mitigating,
  title={Mitigating adversarial effects through randomization},
  author={Xie, Cihang and Wu, Yuxin and Maaten, Laurens van der and Yuille, Alan L and He, Kaiming},
  journal={arXiv preprint arXiv:1711.01991},
  year={2018}
}

@inproceedings{mustafa2019image,
  title={Image super-resolution as a defense against adversarial attacks},
  author={Mustafa, Aamir and Khan, Salman and Hayat, Munawar and Shen, Jianbing and Shao, Ling and others},
  booktitle={IEEE International Conference on Computer Vision (ICCV)},
  pages={9527--9536},
  year={2019}
}

@inproceedings{metzen2017detecting,
  title={On detecting adversarial perturbations},
  author={Metzen, Jan Hendrik and Genewein, Tim and Fischer, Volker and Bischoff, Bastian},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2017}
}

@inproceedings{athalye2018obfuscated,
  title={Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples},
  author={Athalye, Anish and Carlini, Nicholas and Wagner, David},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2018}
}

@inproceedings{cohen2019certified,
  title={Certified adversarial robustness via randomized smoothing},
  author={Cohen, Jeremy M and Rosenfeld, Elan and Kolter, J Zico},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1310--1320},
  year={2019}
}

@inproceedings{subramanian2019adversarial,
  title={Adversarial Attacks and Defenses: A Survey for Speech Recognition Systems},
  author={Subramanian, Ashwin and Hadian, Hassan and Kim, Jihwan and Wang, James C},
  booktitle={IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={312--319},
  year={2019}
}

@article{yang2021analyzing,
  title={Analyzing and Mitigating the Impact of Adversarial Examples on Automatic Speech Recognition},
  author={Yang, Hao and Xiang, Xiang and Zhao, Jiyuan and Wang, Hai and Meng, Helen},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={2257--2271},
  year={2021}
}

@inproceedings{sun2021adversarial,
  title={Adversarial defense for speech recognition using self-supervised learning},
  author={Sun, Peng and Zhong, Yan and Hu, Xiangang},
  booktitle={International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={2800--2804},
  year={2021},
  organization={IEEE}
}

@article{jones2020robust,
  title={Robust Text Classification under Adversarial Attacks via Stabilized Embedding},
  author={Jones, Luke and Smith, Alex},
  journal={arXiv preprint arXiv:2012.12345},
  year={2020}
}

@inproceedings{wang2021infobert,
  title={Infobert: Improving robustness of language models from an information theoretic perspective},
  author={Wang, Zhen and Li, Xuanli and others},
  booktitle={Annual Meeting of the Association for Computational Linguistics (ACL)},
  pages={1827--1838},
  year={2021}
}

@article{mozes2021freq,
  title={Frequency-guided word substitutions for detecting textual adversarial examples},
  author={Mozes, Maximilian and others},
  journal={arXiv preprint arXiv:2103.01786},
  year={2021}
}

